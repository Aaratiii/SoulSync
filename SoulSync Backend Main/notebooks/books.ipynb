{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pymongo\n",
    "from datetime import datetime,date,time\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/self/Best Books Ever.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mongo_db():\n",
    "    mongo_connection = os.environ[\"MONGODB_CONNECTION\"]\n",
    "    client = pymongo.MongoClient(mongo_connection)\n",
    "    return client['recommendation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = get_mongo_db()\n",
    "books_collection = db.get_collection('books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename(columns={\"Book ID\": \"_id\"})\n",
    "data=data.drop(columns=[\"bookFormat\", \"edition\", \"firstPublishDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_value(value):\n",
    "    global unknown_formats\n",
    "    \n",
    "    if pd.isna(value):\n",
    "        return 'NaN'\n",
    "    if isinstance(value, datetime):\n",
    "        return 'datetime'\n",
    "    if isinstance(value, date):\n",
    "      return 'date'\n",
    "    if isinstance(value, int):\n",
    "      return 'int'\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        # Regular expressions for different date formats\n",
    "        patterns = {\n",
    "            \"month day year\": r\"^(January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2}(st|nd|rd|th)? \\d{4}$\",\n",
    "        }\n",
    "        for fmt, pattern in patterns.items():\n",
    "            if re.match(pattern, value):\n",
    "                return fmt\n",
    "        return 'Unknown format'\n",
    "    return f'Invalid type: {type(value).__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value_category\n",
      "month day year    43314\n",
      "int                4362\n",
      "datetime           3017\n",
      "Unknown format      905\n",
      "NaN                 880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the 'publishDate' column and categorize the values\n",
    "data['value_category'] = data['publishDate'].apply(categorize_value)\n",
    "\n",
    "# Count the occurrences of each category\n",
    "category_counts = data['value_category'].value_counts()\n",
    "\n",
    "print(category_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows: 52478\n",
      "Number of rows after dropping NaN values: 51598\n",
      "Number of rows after dropping unknown formats: 50693\n",
      "\n",
      "Remaining value categories:\n",
      "value_category\n",
      "month day year    43314\n",
      "int                4362\n",
      "datetime           3017\n",
      "Name: count, dtype: int64\n",
      "Final number of rows: 50693\n"
     ]
    }
   ],
   "source": [
    "# First, let's see how many rows we have initially\n",
    "print(f\"Initial number of rows: {len(data)}\")\n",
    "\n",
    "# Drop rows where publishDate is NaN\n",
    "data = data.dropna(subset=['publishDate'])\n",
    "print(f\"Number of rows after dropping NaN values: {len(data)}\")\n",
    "\n",
    "# Drop rows where value_category is 'Unknown format'\n",
    "data = data[data['value_category'] != 'Unknown format' ]\n",
    "print(f\"Number of rows after dropping unknown formats: {len(data)}\")\n",
    "\n",
    "# Print the value counts of the remaining categories\n",
    "print(\"\\nRemaining value categories:\")\n",
    "print(data['value_category'].value_counts())\n",
    "\n",
    "# First, let's see how many rows we have initially\n",
    "print(f\"Final number of rows: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of successfully parsed dates: 50693\n",
      "\n",
      "Sample of parsed dates:\n",
      "0    2008-09-14\n",
      "1    2004-09-28\n",
      "2    2006-05-23\n",
      "3    2000-10-10\n",
      "4    2006-09-06\n",
      "Name: publishDate_parsed, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def parse_date(value):\n",
    "    if pd.isna(value):\n",
    "        return pd.NaT\n",
    "    \n",
    "    if isinstance(value, datetime):\n",
    "        return value.date()\n",
    "    \n",
    "    if isinstance(value, (int, float)):\n",
    "        # Assuming the int/float is a Unix timestamp\n",
    "        try:\n",
    "            return pd.to_datetime(value, unit='s').date()\n",
    "        except:\n",
    "            return pd.NaT\n",
    "    \n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "        # Try parsing with dateutil parser\n",
    "        try:\n",
    "            return pd.to_datetime(value).date()\n",
    "        except:\n",
    "            # If dateutil fails, try specific formats\n",
    "            formats = [\n",
    "                \"%B %d %Y\",  # e.g., \"January 1 2023\"\n",
    "                \"%B %d, %Y\",  # e.g., \"January 1, 2023\"\n",
    "                \"%b %d %Y\",   # e.g., \"Jan 1 2023\"\n",
    "                \"%Y-%m-%d\",   # e.g., \"2023-01-01\"\n",
    "                \"%Y-%m-%d %H:%M:%S\"  # e.g., \"2023-01-01 12:00:00\"\n",
    "            ]\n",
    "            for fmt in formats:\n",
    "                try:\n",
    "                    return datetime.strptime(value, fmt).date()\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return pd.NaT\n",
    "\n",
    "# Apply the function to the 'publishDate' column\n",
    "data['publishDate_parsed'] = data['publishDate'].apply(parse_date)\n",
    "\n",
    "# Drop rows where parsing failed (resulted in NaT)\n",
    "data = data.dropna(subset=['publishDate_parsed'])\n",
    "\n",
    "print(f\"Number of successfully parsed dates: {len(data)}\")\n",
    "\n",
    "# Display a sample of the parsed dates\n",
    "print(\"\\nSample of parsed dates:\")\n",
    "print(data['publishDate_parsed'].head())\n",
    "\n",
    "# If you want to reset the index of your DataFrame after dropping rows:\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "publishDate_parsed\n",
      "date    50693\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "26129    2014-10-14\n",
       "37062    2010-11-16\n",
       "22831    2016-06-07\n",
       "29214    2012-05-30\n",
       "17846    2008-04-08\n",
       "Name: publishDate_parsed, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = data['publishDate_parsed'].apply(categorize_value).value_counts()\n",
    "print(count)\n",
    "data['publishDate_parsed'].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['publishDate_parsed'] = data['publishDate_parsed'].apply(lambda x: str(x.isoformat()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['publishDate', 'value_category'])\n",
    "data = data.rename(columns={'publishDate_parsed': 'publishDate'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21397    1970-01-01\n",
       "34948    2014-07-04\n",
       "31207    2011-05-10\n",
       "47110    1987-01-15\n",
       "10973    1992-06-02\n",
       "8793     2016-01-05\n",
       "50627    2012-10-07\n",
       "10572    2015-06-04\n",
       "49108    2007-01-23\n",
       "33892    1999-06-01\n",
       "Name: publishDate, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['publishDate'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where 'title' is a datetime.time object\n",
    "data = data[~data['title'].apply(lambda x: isinstance(x, time))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_genre(genre):\n",
    "  if(isinstance(genre, list)):\n",
    "    return genre\n",
    "  print(genre)\n",
    "  genre = genre.replace(\"'\", \"\\\"\")\n",
    "  try:\n",
    "    g = json.loads(genre)\n",
    "    return g\n",
    "  except Exception as e:\n",
    "    print(e, \"\\n\", genre, type(genre))\n",
    "    raise e\n",
    "  \n",
    "data['genres'] = data['genres'].apply(parse_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2540"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['publisher'] = data['publisher'].replace({'NaN': ''})\n",
    "data['publisher'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['setting', 'series', 'awards'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29903    [Mystery, Vampires, Urban Fantasy, Paranormal,...\n",
       "31597           [Travel, Fiction, Young Adult, Literature]\n",
       "49870    [Economics, Nonfiction, Politics, History, Bus...\n",
       "20871    [Classics, Poetry, Russia, Fiction, Russian Li...\n",
       "2201     [Fiction, Japan, Mystery, Thriller, Japanese L...\n",
       "22130    [Poetry, Romance, Audiobook, LGBT, Nonfiction,...\n",
       "1990     [Fantasy, Young Adult, Urban Fantasy, Paranorm...\n",
       "20602                                                   []\n",
       "39605    [Fantasy, M M Romance, Romance, Paranormal, Ma...\n",
       "41437    [Fantasy, Anthologies, Short Stories, Fiction,...\n",
       "Name: genres, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['genres'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified 0 documents\n",
      "Upserted 0 documents\n"
     ]
    }
   ],
   "source": [
    "# Prepare the bulk operations\n",
    "bulk_operations = []\n",
    "for d in data.to_dict('records'):\n",
    "    bulk_operations.append(\n",
    "        pymongo.UpdateOne(\n",
    "            {\"_id\": d[\"_id\"]},\n",
    "            {\"$set\": d},\n",
    "            upsert=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Execute the bulk operation\n",
    "try:\n",
    "    result = books_collection.bulk_write(bulk_operations)\n",
    "    print(f\"Modified {result.modified_count} documents\")\n",
    "    print(f\"Upserted {result.upserted_count} documents\")\n",
    "except pymongo.BulkWriteError as bwe:\n",
    "    print(f\"Error in bulk write operation: {bwe.details}\")\n",
    "    # Optionally, you can still get stats on successful operations:\n",
    "    if bwe.details.get('nMatched') is not None:\n",
    "        print(f\"Matched {bwe.details['nMatched']} documents\")\n",
    "    if bwe.details.get('nModified') is not None:\n",
    "        print(f\"Modified {bwe.details['nModified']} documents\")\n",
    "    if bwe.details.get('nUpserted') is not None:\n",
    "        print(f\"Upserted {bwe.details['nUpserted']} documents\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soulsync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
